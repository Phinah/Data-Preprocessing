{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Processing Pipeline\n",
        "\n",
        "Complete pipeline for facial image processing, augmentation, and feature extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✗ opencv-python is missing - installing...\n",
            "✓ numpy is already installed\n",
            "✓ pandas is already installed\n",
            "✓ matplotlib is already installed\n",
            "✗ Pillow is missing - installing...\n",
            "✗ scikit-image is missing - installing...\n",
            "✗ scikit-learn is missing - installing...\n",
            "\n",
            "Installing 4 missing packages...\n",
            "Requirement already satisfied: opencv-python in ./.venv/lib/python3.13/site-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in ./.venv/lib/python3.13/site-packages (from opencv-python) (2.2.6)\n",
            "✓ Successfully installed opencv-python\n",
            "Requirement already satisfied: Pillow in ./.venv/lib/python3.13/site-packages (12.0.0)\n",
            "✓ Successfully installed Pillow\n",
            "Requirement already satisfied: scikit-image in ./.venv/lib/python3.13/site-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in ./.venv/lib/python3.13/site-packages (from scikit-image) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.11.4 in ./.venv/lib/python3.13/site-packages (from scikit-image) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.13/site-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in ./.venv/lib/python3.13/site-packages (from scikit-image) (12.0.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in ./.venv/lib/python3.13/site-packages (from scikit-image) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in ./.venv/lib/python3.13/site-packages (from scikit-image) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in ./.venv/lib/python3.13/site-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in ./.venv/lib/python3.13/site-packages (from scikit-image) (0.4)\n",
            "✓ Successfully installed scikit-image\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
            "✓ Successfully installed scikit-learn\n",
            "\n",
            "✓ Installation complete! Please restart the kernel and run cells again.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages if not already installed\n",
        "# Run this cell first if you get ModuleNotFoundError\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    \"\"\"Install a package using pip\"\"\"\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--break-system-packages\", package])\n",
        "\n",
        "# List of required packages\n",
        "required_packages = [\n",
        "    \"opencv-python\",\n",
        "    \"numpy\",\n",
        "    \"pandas\",\n",
        "    \"matplotlib\",\n",
        "    \"Pillow\",\n",
        "    \"scikit-image\",\n",
        "    \"scikit-learn\"\n",
        "]\n",
        "\n",
        "# Check and install missing packages\n",
        "missing_packages = []\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        pkg_name = package.replace(\"-\", \"_\") if \"-\" in package else package\n",
        "        __import__(pkg_name)\n",
        "        print(f\"✓ {package} is already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"✗ {package} is missing - installing...\")\n",
        "        missing_packages.append(package)\n",
        "\n",
        "if missing_packages:\n",
        "    print(f\"\\nInstalling {len(missing_packages)} missing packages...\")\n",
        "    for package in missing_packages:\n",
        "        try:\n",
        "            install_package(package)\n",
        "            print(f\"✓ Successfully installed {package}\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Failed to install {package}: {e}\")\n",
        "    print(\"\\n✓ Installation complete! Please restart the kernel and run cells again.\")\n",
        "else:\n",
        "    print(\"\\n✓ All required packages are installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 image files in Images\n",
            "  - Sage_neutral.jpg\n",
            "  - Sage_smile.jpg\n",
            "  - Sage_surprised.jpg\n"
          ]
        }
      ],
      "source": [
        "# Configuration - Updated for local project structure\n",
        "BASE_DIR = Path(\"Images\")\n",
        "AUG_DIR = BASE_DIR / \"augmented\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "AUG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Define team members\n",
        "team_members = ['Phinah', 'Sage', 'Ayomide', 'Carine']\n",
        "expressions = ['neutral', 'smile', 'surprised']\n",
        "\n",
        "# List available image files\n",
        "image_files = []\n",
        "for member in team_members:\n",
        "    for expr in expressions:\n",
        "        img_path = BASE_DIR / f\"{member}_{expr}.jpg\"\n",
        "        if img_path.exists():\n",
        "            image_files.append(img_path)\n",
        "\n",
        "print(f\"Found {len(image_files)} image files in {BASE_DIR}\")\n",
        "for img in image_files[:6]:  # Show first 6\n",
        "    print(f\"  - {img.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Loading and Display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample image not found: Images/Phinah_neutral.jpg\n"
          ]
        }
      ],
      "source": [
        "# Load and display a sample image\n",
        "def load_image(image_path):\n",
        "    \"\"\"Load image from file\"\"\"\n",
        "    img = cv2.imread(str(image_path))\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Could not load image: {image_path}\")\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Example: Load Phinah's neutral image\n",
        "sample_path = BASE_DIR / \"Phinah_neutral.jpg\"\n",
        "if sample_path.exists():\n",
        "    img = load_image(sample_path)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Sample Image: {sample_path.name}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(f\"Image shape: {img.shape}\")\n",
        "else:\n",
        "    print(f\"Sample image not found: {sample_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Augmentation functions defined\n"
          ]
        }
      ],
      "source": [
        "# Augmentation functions\n",
        "\n",
        "def augment_rotation(image, angle=15):\n",
        "    \"\"\"Rotate image by specified angle\"\"\"\n",
        "    height, width = image.shape[:2]\n",
        "    center = (width // 2, height // 2)\n",
        "    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, matrix, (width, height))\n",
        "    return rotated\n",
        "\n",
        "def augment_flip(image, flip_code=1):\n",
        "    \"\"\"Flip image (0=vertical, 1=horizontal, -1=both)\"\"\"\n",
        "    return cv2.flip(image, flip_code)\n",
        "\n",
        "def augment_grayscale(image):\n",
        "    \"\"\"Convert to grayscale\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    return image\n",
        "\n",
        "def augment_brightness(image, factor=1.5):\n",
        "    \"\"\"Adjust brightness\"\"\"\n",
        "    bright = image.astype(np.float32) * factor\n",
        "    bright = np.clip(bright, 0, 255).astype(np.uint8)\n",
        "    return bright\n",
        "\n",
        "def augment_noise(image, noise_level=25):\n",
        "    \"\"\"Add noise to image\"\"\"\n",
        "    noise = np.random.randint(-noise_level, noise_level, image.shape, dtype=np.int16)\n",
        "    noisy = image.astype(np.int16) + noise\n",
        "    noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
        "    return noisy\n",
        "\n",
        "print(\"✓ Augmentation functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply augmentations to a sample image\n",
        "sample_path = BASE_DIR / \"Phinah_neutral.jpg\"\n",
        "if sample_path.exists():\n",
        "    original = load_image(sample_path)\n",
        "    \n",
        "    # Apply augmentations\n",
        "    rotated = augment_rotation(original, angle=15)\n",
        "    flipped = augment_flip(original)\n",
        "    grayscale = augment_grayscale(original)\n",
        "    bright = augment_brightness(original, factor=1.3)\n",
        "    noisy = augment_noise(original, noise_level=20)\n",
        "    \n",
        "    # Display all versions\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes[0, 0].imshow(original)\n",
        "    axes[0, 0].set_title('Original')\n",
        "    axes[0, 0].axis('off')\n",
        "    \n",
        "    axes[0, 1].imshow(rotated)\n",
        "    axes[0, 1].set_title('Rotated (15°)')\n",
        "    axes[0, 1].axis('off')\n",
        "    \n",
        "    axes[0, 2].imshow(flipped)\n",
        "    axes[0, 2].set_title('Flipped')\n",
        "    axes[0, 2].axis('off')\n",
        "    \n",
        "    axes[1, 0].imshow(grayscale, cmap='gray')\n",
        "    axes[1, 0].set_title('Grayscale')\n",
        "    axes[1, 0].axis('off')\n",
        "    \n",
        "    axes[1, 1].imshow(bright)\n",
        "    axes[1, 1].set_title('Brightness Adjusted')\n",
        "    axes[1, 1].axis('off')\n",
        "    \n",
        "    axes[1, 2].imshow(noisy)\n",
        "    axes[1, 2].set_title('Noisy')\n",
        "    axes[1, 2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sample_images_display.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"Display saved as 'sample_images_display.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Feature extraction functions defined\n"
          ]
        }
      ],
      "source": [
        "# Feature extraction functions\n",
        "from skimage.feature import hog, local_binary_pattern\n",
        "\n",
        "def extract_histogram_features(image):\n",
        "    \"\"\"Extract histogram features for each channel\"\"\"\n",
        "    if len(image.shape) == 2:\n",
        "        # Grayscale image\n",
        "        hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
        "        return hist.flatten()\n",
        "    else:\n",
        "        # Color image - extract for each channel\n",
        "        features = []\n",
        "        for i in range(3):\n",
        "            hist = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
        "            features.extend(hist.flatten())\n",
        "        return np.array(features)\n",
        "\n",
        "def extract_hog_features(image):\n",
        "    \"\"\"Extract HOG (Histogram of Oriented Gradients) features\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "    \n",
        "    # Resize to standard size for HOG\n",
        "    gray_resized = cv2.resize(gray, (128, 128))\n",
        "    \n",
        "    # Extract HOG features\n",
        "    features = hog(gray_resized, orientations=9, pixels_per_cell=(8, 8),\n",
        "                   cells_per_block=(2, 2), feature_vector=True)\n",
        "    return features\n",
        "\n",
        "def extract_lbp_features(image, radius=3, n_points=24):\n",
        "    \"\"\"Extract LBP (Local Binary Pattern) features\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "    \n",
        "    # Extract LBP\n",
        "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
        "    \n",
        "    # Calculate histogram\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=n_points + 2, range=(0, n_points + 2))\n",
        "    hist = hist.astype(float)\n",
        "    hist /= (hist.sum() + 1e-7)  # Normalize\n",
        "    \n",
        "    return hist\n",
        "\n",
        "def extract_color_moments(image):\n",
        "    \"\"\"Extract color moments (mean, std, skewness) for each channel\"\"\"\n",
        "    if len(image.shape) == 2:\n",
        "        image = image[:, :, np.newaxis]\n",
        "    \n",
        "    features = []\n",
        "    for i in range(3):\n",
        "        channel = image[:, :, i].flatten()\n",
        "        mean = np.mean(channel)\n",
        "        std = np.std(channel)\n",
        "        skewness = np.mean(((channel - mean) / (std + 1e-7)) ** 3)\n",
        "        features.extend([mean, std, skewness])\n",
        "    \n",
        "    return np.array(features)\n",
        "\n",
        "print(\"✓ Feature extraction functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features from a sample image\n",
        "sample_path = BASE_DIR / \"Phinah_neutral.jpg\"\n",
        "if sample_path.exists():\n",
        "    img = load_image(sample_path)\n",
        "    \n",
        "    hist_features = extract_histogram_features(img)\n",
        "    hog_features = extract_hog_features(img)\n",
        "    lbp_features = extract_lbp_features(img)\n",
        "    color_moments = extract_color_moments(img)\n",
        "    \n",
        "    print(f\"Histogram features: {len(hist_features)} dimensions\")\n",
        "    print(f\"HOG features: {len(hog_features)} dimensions\")\n",
        "    print(f\"LBP features: {len(lbp_features)} dimensions\")\n",
        "    print(f\"Color moments: {len(color_moments)} dimensions\")\n",
        "    print(f\"\\nTotal features: {len(hist_features) + len(hog_features) + len(lbp_features) + len(color_moments)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process All Images and Extract Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Processing function defined\n"
          ]
        }
      ],
      "source": [
        "# Process all team member images\n",
        "def process_member_images(member_name, expressions=['neutral', 'smile', 'surprised']):\n",
        "    \"\"\"Process all images for a team member\"\"\"\n",
        "    features_list = []\n",
        "    \n",
        "    for expression in expressions:\n",
        "        img_path = BASE_DIR / f\"{member_name}_{expression}.jpg\"\n",
        "        \n",
        "        if not img_path.exists():\n",
        "            print(f\"Warning: Image for {member_name} {expression} not found, skipping...\")\n",
        "            continue\n",
        "        \n",
        "        # Load original image\n",
        "        original = load_image(img_path)\n",
        "        \n",
        "        # Apply augmentations\n",
        "        rotated = augment_rotation(original, angle=15)\n",
        "        flipped = augment_flip(original)\n",
        "        grayscale = augment_grayscale(original)\n",
        "        bright = augment_brightness(original, factor=1.3)\n",
        "        noisy = augment_noise(original, noise_level=20)\n",
        "        \n",
        "        # Save augmented images\n",
        "        aug_dir = AUG_DIR / member_name\n",
        "        aug_dir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        cv2.imwrite(str(aug_dir / f\"{expression}_rotated.jpg\"), \n",
        "                   cv2.cvtColor(rotated, cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(str(aug_dir / f\"{expression}_flipped.jpg\"), \n",
        "                   cv2.cvtColor(flipped, cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(str(aug_dir / f\"{expression}_grayscale.jpg\"), grayscale)\n",
        "        cv2.imwrite(str(aug_dir / f\"{expression}_bright.jpg\"), \n",
        "                   cv2.cvtColor(bright, cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(str(aug_dir / f\"{expression}_noisy.jpg\"), \n",
        "                   cv2.cvtColor(noisy, cv2.COLOR_RGB2BGR))\n",
        "        \n",
        "        # Process all versions (original + augmented)\n",
        "        versions = [\n",
        "            ('original', original),\n",
        "            ('rotated', rotated),\n",
        "            ('flipped', flipped),\n",
        "            ('grayscale', cv2.cvtColor(grayscale, cv2.COLOR_GRAY2RGB) if len(grayscale.shape) == 2 else grayscale),\n",
        "            ('bright', bright),\n",
        "            ('noisy', noisy)\n",
        "        ]\n",
        "        \n",
        "        for aug_type, img in versions:\n",
        "            # Extract features\n",
        "            hist_features = extract_histogram_features(img)\n",
        "            hog_features = extract_hog_features(img)\n",
        "            lbp_features = extract_lbp_features(img)\n",
        "            color_moments = extract_color_moments(img)\n",
        "            \n",
        "            # Create feature dictionary\n",
        "            feature_dict = {\n",
        "                'member_name': member_name,\n",
        "                'expression': expression,\n",
        "                'augmentation': aug_type,\n",
        "                'image_path': str(img_path)\n",
        "            }\n",
        "            \n",
        "            # Add histogram features (reduced for CSV)\n",
        "            hist_reduced = hist_features[::10]  # Sample every 10th value\n",
        "            for i, val in enumerate(hist_reduced):\n",
        "                feature_dict[f'hist_{i}'] = val\n",
        "            \n",
        "            # Add HOG features (reduced)\n",
        "            hog_reduced = hog_features[::50]  # Sample every 50th value\n",
        "            for i, val in enumerate(hog_reduced):\n",
        "                feature_dict[f'hog_{i}'] = val\n",
        "            \n",
        "            # Add LBP features (reduced)\n",
        "            lbp_reduced = lbp_features[::10]\n",
        "            for i, val in enumerate(lbp_reduced):\n",
        "                feature_dict[f'lbp_{i}'] = val\n",
        "            \n",
        "            # Add color moments\n",
        "            for i, val in enumerate(color_moments):\n",
        "                feature_dict[f'color_moment_{i}'] = val\n",
        "            \n",
        "            # Add mean and std intensity\n",
        "            feature_dict['mean_intensity'] = np.mean(img)\n",
        "            feature_dict['std_intensity'] = np.std(img)\n",
        "            \n",
        "            features_list.append(feature_dict)\n",
        "    \n",
        "    return features_list\n",
        "\n",
        "print(\"✓ Processing function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "IMAGE PROCESSING PIPELINE\n",
            "============================================================\n",
            "\n",
            "Processing images for Phinah...\n",
            "Warning: Image for Phinah neutral not found, skipping...\n",
            "Warning: Image for Phinah smile not found, skipping...\n",
            "Warning: Image for Phinah surprised not found, skipping...\n",
            "  ✗ No features extracted for Phinah.\n",
            "\n",
            "Processing images for Sage...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✓ Processed 18 image versions\n",
            "\n",
            "Processing images for Ayomide...\n",
            "Warning: Image for Ayomide neutral not found, skipping...\n",
            "Warning: Image for Ayomide smile not found, skipping...\n",
            "Warning: Image for Ayomide surprised not found, skipping...\n",
            "  ✗ No features extracted for Ayomide.\n",
            "\n",
            "Processing images for Carine...\n",
            "Warning: Image for Carine neutral not found, skipping...\n",
            "Warning: Image for Carine smile not found, skipping...\n",
            "Warning: Image for Carine surprised not found, skipping...\n",
            "  ✗ No features extracted for Carine.\n",
            "\n",
            "============================================================\n",
            "Feature extraction complete!\n",
            "Total samples processed: 18\n",
            "Features saved to: image_features.csv\n",
            "Shape: (18, 257)\n",
            "\n",
            "Feature columns: 257 total\n",
            "============================================================\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>member_name</th>\n",
              "      <th>expression</th>\n",
              "      <th>augmentation</th>\n",
              "      <th>image_path</th>\n",
              "      <th>hist_0</th>\n",
              "      <th>hist_1</th>\n",
              "      <th>hist_2</th>\n",
              "      <th>hist_3</th>\n",
              "      <th>hist_4</th>\n",
              "      <th>hist_5</th>\n",
              "      <th>...</th>\n",
              "      <th>color_moment_1</th>\n",
              "      <th>color_moment_2</th>\n",
              "      <th>color_moment_3</th>\n",
              "      <th>color_moment_4</th>\n",
              "      <th>color_moment_5</th>\n",
              "      <th>color_moment_6</th>\n",
              "      <th>color_moment_7</th>\n",
              "      <th>color_moment_8</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>std_intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sage</td>\n",
              "      <td>neutral</td>\n",
              "      <td>original</td>\n",
              "      <td>Images/Sage_neutral.jpg</td>\n",
              "      <td>123689.0</td>\n",
              "      <td>65478.0</td>\n",
              "      <td>12432.0</td>\n",
              "      <td>3225.0</td>\n",
              "      <td>3539.0</td>\n",
              "      <td>2185.0</td>\n",
              "      <td>...</td>\n",
              "      <td>90.701655</td>\n",
              "      <td>-0.558957</td>\n",
              "      <td>135.483085</td>\n",
              "      <td>88.821060</td>\n",
              "      <td>-0.498212</td>\n",
              "      <td>128.527743</td>\n",
              "      <td>81.468677</td>\n",
              "      <td>-0.441991</td>\n",
              "      <td>134.298470</td>\n",
              "      <td>87.194903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sage</td>\n",
              "      <td>neutral</td>\n",
              "      <td>rotated</td>\n",
              "      <td>Images/Sage_neutral.jpg</td>\n",
              "      <td>637445.0</td>\n",
              "      <td>63828.0</td>\n",
              "      <td>9274.0</td>\n",
              "      <td>3146.0</td>\n",
              "      <td>3462.0</td>\n",
              "      <td>2145.0</td>\n",
              "      <td>...</td>\n",
              "      <td>96.511347</td>\n",
              "      <td>-0.205652</td>\n",
              "      <td>117.756013</td>\n",
              "      <td>94.362501</td>\n",
              "      <td>-0.160691</td>\n",
              "      <td>112.130732</td>\n",
              "      <td>86.927451</td>\n",
              "      <td>-0.130177</td>\n",
              "      <td>116.811884</td>\n",
              "      <td>92.757521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sage</td>\n",
              "      <td>neutral</td>\n",
              "      <td>flipped</td>\n",
              "      <td>Images/Sage_neutral.jpg</td>\n",
              "      <td>123689.0</td>\n",
              "      <td>65478.0</td>\n",
              "      <td>12432.0</td>\n",
              "      <td>3225.0</td>\n",
              "      <td>3539.0</td>\n",
              "      <td>2185.0</td>\n",
              "      <td>...</td>\n",
              "      <td>90.701655</td>\n",
              "      <td>-0.558957</td>\n",
              "      <td>135.483085</td>\n",
              "      <td>88.821060</td>\n",
              "      <td>-0.498212</td>\n",
              "      <td>128.527743</td>\n",
              "      <td>81.468677</td>\n",
              "      <td>-0.441991</td>\n",
              "      <td>134.298470</td>\n",
              "      <td>87.194903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sage</td>\n",
              "      <td>neutral</td>\n",
              "      <td>grayscale</td>\n",
              "      <td>Images/Sage_neutral.jpg</td>\n",
              "      <td>29964.0</td>\n",
              "      <td>59952.0</td>\n",
              "      <td>67950.0</td>\n",
              "      <td>4440.0</td>\n",
              "      <td>2606.0</td>\n",
              "      <td>3260.0</td>\n",
              "      <td>...</td>\n",
              "      <td>88.445758</td>\n",
              "      <td>-0.509313</td>\n",
              "      <td>135.682974</td>\n",
              "      <td>88.445758</td>\n",
              "      <td>-0.509313</td>\n",
              "      <td>135.682974</td>\n",
              "      <td>88.445758</td>\n",
              "      <td>-0.509313</td>\n",
              "      <td>135.682974</td>\n",
              "      <td>88.445758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sage</td>\n",
              "      <td>neutral</td>\n",
              "      <td>bright</td>\n",
              "      <td>Images/Sage_neutral.jpg</td>\n",
              "      <td>123689.0</td>\n",
              "      <td>62453.0</td>\n",
              "      <td>73252.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3325.0</td>\n",
              "      <td>3702.0</td>\n",
              "      <td>...</td>\n",
              "      <td>108.293206</td>\n",
              "      <td>-0.629258</td>\n",
              "      <td>166.540795</td>\n",
              "      <td>107.416657</td>\n",
              "      <td>-0.559154</td>\n",
              "      <td>162.980590</td>\n",
              "      <td>102.411799</td>\n",
              "      <td>-0.479724</td>\n",
              "      <td>166.105985</td>\n",
              "      <td>106.099214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 257 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  member_name expression augmentation               image_path    hist_0  \\\n",
              "0        Sage    neutral     original  Images/Sage_neutral.jpg  123689.0   \n",
              "1        Sage    neutral      rotated  Images/Sage_neutral.jpg  637445.0   \n",
              "2        Sage    neutral      flipped  Images/Sage_neutral.jpg  123689.0   \n",
              "3        Sage    neutral    grayscale  Images/Sage_neutral.jpg   29964.0   \n",
              "4        Sage    neutral       bright  Images/Sage_neutral.jpg  123689.0   \n",
              "\n",
              "    hist_1   hist_2  hist_3  hist_4  hist_5  ...  color_moment_1  \\\n",
              "0  65478.0  12432.0  3225.0  3539.0  2185.0  ...       90.701655   \n",
              "1  63828.0   9274.0  3146.0  3462.0  2145.0  ...       96.511347   \n",
              "2  65478.0  12432.0  3225.0  3539.0  2185.0  ...       90.701655   \n",
              "3  59952.0  67950.0  4440.0  2606.0  3260.0  ...       88.445758   \n",
              "4  62453.0  73252.0     0.0  3325.0  3702.0  ...      108.293206   \n",
              "\n",
              "   color_moment_2  color_moment_3  color_moment_4  color_moment_5  \\\n",
              "0       -0.558957      135.483085       88.821060       -0.498212   \n",
              "1       -0.205652      117.756013       94.362501       -0.160691   \n",
              "2       -0.558957      135.483085       88.821060       -0.498212   \n",
              "3       -0.509313      135.682974       88.445758       -0.509313   \n",
              "4       -0.629258      166.540795      107.416657       -0.559154   \n",
              "\n",
              "   color_moment_6  color_moment_7  color_moment_8  mean_intensity  \\\n",
              "0      128.527743       81.468677       -0.441991      134.298470   \n",
              "1      112.130732       86.927451       -0.130177      116.811884   \n",
              "2      128.527743       81.468677       -0.441991      134.298470   \n",
              "3      135.682974       88.445758       -0.509313      135.682974   \n",
              "4      162.980590      102.411799       -0.479724      166.105985   \n",
              "\n",
              "   std_intensity  \n",
              "0      87.194903  \n",
              "1      92.757521  \n",
              "2      87.194903  \n",
              "3      88.445758  \n",
              "4     106.099214  \n",
              "\n",
              "[5 rows x 257 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Process all team members\n",
        "print(\"=\"*60)\n",
        "print(\"IMAGE PROCESSING PIPELINE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_features = []\n",
        "for member in team_members:\n",
        "    print(f\"\\nProcessing images for {member}...\")\n",
        "    member_features = process_member_images(member)\n",
        "    if member_features:\n",
        "        all_features.extend(member_features)\n",
        "        print(f\"  ✓ Processed {len(member_features)} image versions\")\n",
        "    else:\n",
        "        print(f\"  ✗ No features extracted for {member}.\")\n",
        "\n",
        "if all_features:\n",
        "    df_features = pd.DataFrame(all_features)\n",
        "    df_features.to_csv('image_features.csv', index=False)\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Feature extraction complete!\")\n",
        "    print(f\"Total samples processed: {len(all_features)}\")\n",
        "    print(f\"Features saved to: image_features.csv\")\n",
        "    print(f\"Shape: {df_features.shape}\")\n",
        "    print(f\"\\nFeature columns: {len(df_features.columns)} total\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Display first few rows\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    display(df_features.head())\n",
        "else:\n",
        "    print(\"No images were processed. Check your image directory and file names.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "PROCESSING SUMMARY\n",
            "============================================================\n",
            "\n",
            "Team members processed: 4\n",
            "Expressions per member: 3\n",
            "Augmentations per image: 5 (rotated, flipped, grayscale, bright, noisy)\n",
            "Total image versions: 18\n",
            "\n",
            "Output files:\n",
            "  - image_features.csv: Feature matrix\n",
            "  - Images/augmented/: Augmented images\n",
            "  - sample_images_display.png: Visualization\n",
            "\n",
            "Next steps:\n",
            "  1. Review image_features.csv\n",
            "  2. Train facial recognition model: python train_face_model.py\n",
            "  3. Test face verification: python verify_face.py Images/Phinah_neutral.jpg\n"
          ]
        }
      ],
      "source": [
        "# Summary\n",
        "print(\"=\"*60)\n",
        "print(\"PROCESSING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTeam members processed: {len(team_members)}\")\n",
        "print(f\"Expressions per member: {len(expressions)}\")\n",
        "print(f\"Augmentations per image: 5 (rotated, flipped, grayscale, bright, noisy)\")\n",
        "print(f\"Total image versions: {len(all_features) if all_features else 0}\")\n",
        "print(f\"\\nOutput files:\")\n",
        "print(f\"  - image_features.csv: Feature matrix\")\n",
        "print(f\"  - Images/augmented/: Augmented images\")\n",
        "print(f\"  - sample_images_display.png: Visualization\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"  1. Review image_features.csv\")\n",
        "print(\"  2. Train facial recognition model: python train_face_model.py\")\n",
        "print(\"  3. Test face verification: python verify_face.py Images/Phinah_neutral.jpg\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
